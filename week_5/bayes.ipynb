{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Part: Naive Bayes and AdaBoost in Agronomy\n",
    "\n",
    "In this practical session, we will implement Naive Bayes and AdaBoost classifiers. We'll simulate agronomy-related data to illustrate how these methods work in predicting crop health based on features like soil moisture, leaf color, and pest presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "\n",
    "Let's create a synthetic dataset where:\n",
    "- Each row represents a plant observation.\n",
    "- Features include `soil_moisture`, `leaf_color`, and `pest_presence`.\n",
    "- The target variable is `health`, with classes \"healthy\" and \"unhealthy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soil_moisture</th>\n",
       "      <th>leaf_color</th>\n",
       "      <th>pest_presence</th>\n",
       "      <th>health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>brown</td>\n",
       "      <td>absent</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>brown</td>\n",
       "      <td>present</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>brown</td>\n",
       "      <td>absent</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>green</td>\n",
       "      <td>present</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low</td>\n",
       "      <td>brown</td>\n",
       "      <td>absent</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  soil_moisture leaf_color pest_presence     health\n",
       "0          high      brown        absent  unhealthy\n",
       "1           low      brown       present  unhealthy\n",
       "2          high      brown        absent    healthy\n",
       "3          high      green       present  unhealthy\n",
       "4           low      brown        absent    healthy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulating a dataset with agronomy-related features\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'soil_moisture': np.random.choice(['low', 'medium', 'high'], size=100),\n",
    "    'leaf_color': np.random.choice(['green', 'yellow', 'brown'], size=100),\n",
    "    'pest_presence': np.random.choice(['present', 'absent'], size=100),\n",
    "    'health': np.random.choice(['healthy', 'unhealthy'], size=100)\n",
    "})\n",
    "\n",
    "# Preview of the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables\n",
    "\n",
    "Since Naive Bayes and AdaBoost require numerical input, we will convert our categorical features into numeric form using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=['soil_moisture', 'leaf_color', 'pest_presence'])\n",
    "X = data_encoded.drop('health', axis=1)\n",
    "y = data['health'].apply(lambda x: 1 if x == 'healthy' else 0)  # Encoding target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset\n",
    "\n",
    "We’ll split our data into training and testing sets to check our model’s performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "We’ll train a Naive Bayes model on the training data to classify plant health.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70        11\n",
      "           1       0.64      0.78      0.70         9\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.71      0.71      0.70        20\n",
      "weighted avg       0.71      0.70      0.70        20\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7 4]\n",
      " [2 7]]\n"
     ]
    }
   ],
   "source": [
    "# Training the Naive Bayes classifier\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and evaluating the Naive Bayes model\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Life Example with Naive Bayes\n",
    "\n",
    "Imagine we're classifying crop health based on leaf color and soil moisture. A farmer notices that plants with yellow leaves and low soil moisture often become unhealthy. Naive Bayes helps quantify this by estimating probabilities, assuming each feature independently contributes to crop health.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier\n",
    "\n",
    "Now, let's use an AdaBoost classifier to improve our plant health prediction. We'll use a Decision Tree as the weak learner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.75\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        11\n",
      "           1       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.75      0.74      0.74        20\n",
      "weighted avg       0.75      0.75      0.75        20\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9 2]\n",
      " [3 6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training the AdaBoost classifier\n",
    "ada_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and evaluating the AdaBoost model\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_ada))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Life Example with AdaBoost\n",
    "\n",
    "Imagine a scenario where we’re classifying crop health based on several observations. With AdaBoost, each model learns to focus on cases it misclassified in the past, gradually building a more accurate model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Naive Bayes and AdaBoost\n",
    "\n",
    "| Model        | Naive Bayes Accuracy | AdaBoost Accuracy |\n",
    "|--------------|-----------------------|-------------------|\n",
    "| Score        |       70%             |       75%         |\n",
    "  \n",
    " As expected, AdaBoost has a higher accuracy because it corrects mistakes iteratively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.70\n",
      "AdaBoost Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Displaying the comparison\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_score(y_test, y_pred_nb):.2f}\")\n",
    "print(f\"AdaBoost Accuracy: {accuracy_score(y_test, y_pred_ada):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- **Naive Bayes** is effective for simple, independent features, but it may be limited by its assumptions.\n",
    "- **AdaBoost** improves accuracy by iteratively focusing on misclassified instances, making it powerful for complex data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
